kairosdb: {

	# To set the traffic type allowed for the server, change the kairosdb.server.type entry to INGEST, QUERY, or DELETE,
	# or a comma delimited list of two of them to enable different sets of API methods.
	# The default setting is ALL, which will enable all API methods.
	#server.type: "ALL"

	# Custom tags are no longer defined in kairosdb.conf
	# if you have previously set metrics.custom_tags you can do so in the
	# metrics4j.conf file instead as all internal metrics are now reported
	# through metrics4j

	# Properties that start with kairosdb.service are services that are started
	# when kairos starts up.  Some services are set by default.  You can disable
	# services in your custom kairosdb.conf file by setting the value to <disabled>
	# ie kairosdb.service.telnet=<disabled>

	# Allows you to override the name of the host. This is used to tag internal
	# metrics as well as identifying the host in some services.
	#hostname: "localhost"

	# Changes the prefix used for kairos internal metrics.  This is defined here
	# and passed to metrics4j so that kairos internals can make use of this prefix
	metric-prefix: "kairosdb."

	service.telnet: "org.kairosdb.core.telnet.TelnetServerModule"
	telnetserver: {
		port: 4242
		address: "0.0.0.0"
		max_command_size: 1024
	}

	#===============================================================================
	service.http = org.kairosdb.core.http.WebServletModule
	jetty: {
		# Set to 0 to turn off HTTP port
		port: 8080
		address: "0.0.0.0"
		#timeout for idle sockets between requests.
		socket_idle_timeout: 120000
		static_web_root: "webroot"

		# Show stack trace for debug
		show_stacktrace: false

		# To enable SSL uncomment the following lines and specify the path to the keyStore and its password and port
		#ssl: {
		#port: 443
		#protocols: "TLSv1.1, TLSv1.2"
		#cipherSuites: "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_EMPTY_RENEGOTIATION_INFO_SCSV"
		#keystore.path=
		#keystore.password=
		#Truststore may need to be set if you are using a form of auth that uses another server/service for authentication
		#You may need to add a truststore with that servers certificate so KairosDB can connect to that server.
		#truststore.path=
		#}

		# To enable Jetty Request Logging uncomment the following lines. Such logging configuration is detailed here https://www.eclipse.org/jetty/documentation/current/configuring-jetty-request-logs.html
		# Days to retain the logs defaults to 30 if it is not set.
		# ignore_paths allows you set which paths you want jetty to not log if any. The below would cause jetty to not log calls made to the version and health endpoints.
		#request_logging: {
		#enabled: true
		#retain_days: 30
		#ignore_paths: ["/api/v1/version", "/api/v1/health/*"]
		#}

		# KairosDB now uses the Jetty JAAS Framework to do Authentication. You can extend the Jetty JAAS framework to do many kinds of authentication.
		# Under the auth folder you will find 3 files that allow configuration of file based basic auth or LDAP auth
		# Samples of how to configure the various auth versions can be found here https://www.eclipse.org/jetty/documentation/current/jaas-support.html
		# basicAuth.conf and auth.props will configure the PropertyFileLoginModule and ldap-loginModule.conf will configure the ldap module.
		# the auth_module_name below should match the name outside the curly braces in the respective conf file.
		# The basics of how to configure two or more modules to work together in logic and/or combinations can be found here https://docs.oracle.com/javase/8/docs/api/javax/security/auth/login/Configuration.html and here https://github.com/rundeck/rundeck/wiki/Multiple-authentication-modules
		#auth_module_name: "basicAuth"

		# To enable thread pooling uncomment the following lines and specify the limits
		#threads.queue_size: 6000
		#threads.min: 1000
		#threads.max: 2500
		#threads.keep_alive_ms: 10000
	}

	#===============================================================================
	# Each factory must be bound in a guice module.  The definition here defines what
	# protocol data type the factory services.
	datapoints.factory: {
		# Default data point implementation for long - class must implement LongDataPointFactory
		long: "org.kairosdb.core.datapoints.LongDataPointFactoryImpl"
		# Default data point implementation for double - class must implement DoubleDataPointFactory
		double: "org.kairosdb.core.datapoints.DoubleDataPointFactoryImpl"
		string: "org.kairosdb.core.datapoints.StringDataPointFactory"
	}

	#===============================================================================
	service.reporter = org.kairosdb.core.reporting.MetricReportingModule
	reporter: {
		# Uses Quartz Cron syntax - default is to run every minute
		schedule: "0 */1 * * * ?"
		# TTL to apply to all kairos reported metrics
		ttl: 0
	}

	#===============================================================================
	#Configure the datastore

	service.datastore: "org.kairosdb.datastore.h2.H2Module"
	#service.datastore: "org.kairosdb.datastore.cassandra.CassandraModule"

	datastore.concurrentQueryThreads: 5

	datastore.h2.database_path: "build/h2db"

	datastore.cassandra: {

		#This lets you add additional parameters to the CQL create statement
		#For example if you want to change compression or compaction strategies
		#This only takes effect the first time Kairos starts and tries to create
		#the tables if they do not exist
		table_create_with: {
			data_points: "WITH COMPACT STORAGE"
			row_key_index: ""
			row_key_time_index: ""
			row_keys: ""
			tag_indexed_row_keys: ""
			string_index: ""
			service_index: ""
		}

		#For a single metric query this dictates the number of simultaneous cql queries
		#to run (ie one for each partition key of data).  The larger the cluster the higher you may want
		#this number to be.
		simultaneous_cql_queries: 20

		# query_reader_threads is the number of threads to use to read results from
		# each cql query.  You may want to change this number depending on your environment
		query_reader_threads: 6

		# When set, the query_limit will prevent any query reading more than the specified
		# number of data points.  When the limit is reached an exception is thrown and an
		# error is returned to the client.  Set this value to 0 to disable (default)
		#query_limit: 10000000

		# When set, the query_time_limit_sec will try to prevent any query from taking
		# longer than the number of seconds specified.  This time is measuered while
		# doing actual work against Cassandra.  A query could be blocked on slower queries
		# at a higher level and actually take longer than the specified time.
		#query_time_limit_sec: 60

		//Todo this is wrong
		#Size of the row key cache size.  This can be monitored by querying
		#kairosdb.datastore.cassandra.write_batch_size.sum and filtering on the tag table = row_keys
		#Ideally the data written to the row_keys should stabilize to zero except
		#when data rolls to a new row
		row_key_cache_size: 50000
		string_cache_size: 50000

		#the time to live in seconds for datapoints. After this period the data will be
		#deleted automatically. If not set the data will live forever.
		#TTLs are added to columns as they're inserted so setting this will not affect
		#existing data, only new data.
		#datapoint_ttl: 31536000

		#When start_async is set to true a background thread is created to try and
		#connect to cassandra when starting up Kairos.  This allows Kairos to start
		#even if Cassandra is not yet available.  The background thread repeatedly
		#attempts to connect every 1sec until it is successful.
		#Setting start_async to false means kairos will fail to start if Cassandra
		#is not available.
		start_async: false

		# This identifies the cluster, metrics are written to.  The write_cluster also
		# participates in any metric query.  If you only have one C* cluster then
		# it must be specified as the write_cluster
		write_cluster: {
			config_prefix: "write_cluster"

			replication: "{'class': 'SimpleStrategy','replication_factor' : 1}"

			# Set this property to a list of metric names for which the tag-indexed row key lookup table should be used
			# to improve query speed when high-cardinality tags are involved. Setting this to a single entry of ['*']
			# will enable it for all metrics.
			# Turning this on can significantly increase the number of writes to Cassandra.
			# Row keys in Cassandra should only be written once every 3 weeks for
			# every unique tag combination, if your cache is large enough.
			# Say you have a metric with 3 tags: inserting a value with tags not seen
			# before will generate 2 inserts, one for the data and one for the row index.
			# If you turn on the tag index lookup for that metric it will create 5 inserts,
			# same as before with one for for each tag.
			# The property can be set as a list of metric names where all tags get indexed
			# or it can be an object where you specify the tags to index for each metric
			# tag_indexed_row_key_lookup_metrics: {
			#   metric1: [ tag1 ]
			#   metric2: [ * ]
			#   metric3: []
			#   }
			# Only tag1 for metric1 will be indexed.  For metric2 and metric3 all tags will be indexed.
			# If you migrate this to a read cluster you will need to copy the index config to the read_cluster section.
			tag_indexed_row_key_lookup_metrics: {}

			# The row_time_unit and row_width configurations are one time use and only read
			# from a write cluster configuration.  These configurations are used when
			# creating the schema and how data is written to Cassandra.
			# row_time_unit - can either be set to SECONDS or MILLISECONDS and
			# determines the granularity of the data stored in Cassandra.  If set to
			# SECONDS data sent to Kairos will still be sent according to the API used
			# and millisecond timestamps will be trucated to seconds.
			# The row_width parameter determines how wide the rows are in Cassandra, in
			# other words how long data is written to a row.  The default is just about
			# 3 weeks.
			#row_time_unit: "MILLISECONDS"
			#row_width: 1814400000
		}

		# Rename this to read_clusters in order for it to be used
		# This is for additional clusters of old data that you want to make available
		# for queries.  The cql_host_list SHOULD NOT point to the same cluster as
		# the write_cluster above.
		# All properties found in the write_cluster section can be used here as well
		# As this property is a list you can specify 0 or more read clusters.
		# The idea behind read_clusters is so you can manage data growth, so instead
		# of adding more nodes to an older C* cluster you can create new clusters
		# on newer versions of C*.  Older clusters can then be turned off or shrunk.
		read_clusters_not: [
			{
				name: "read_cluster"
				keyspace: "kairosdb"
				replication: "{'class': 'SimpleStrategy','replication_factor' : 1}"
				//cql_host_list: ["kairos01", "kairos02", "kairos03"]
				cql_host_list: ["localhost"]
				#local_dc_name: "<local dc name>
				read_consistency_level: "ONE"
				write_consistency_level: "QUORUM"

				connections_per_host: {
					local.core: 5
					local.max: 100
					remote.core: 1
					remote.max: 10
				}

				max_requests_per_connection: {
					local: 128
					remote: 128
				}

				max_queue_size: 500
				use_ssl: false

				# Start and end date are optional configuration parameters
				# The start and end date set bounds on the data in this cluster
				# queries that do not include this time range will not be sent
				# to this cluster.
				start_time: "2001-07-04T12:08-0700"
				end_time: "2001-07-04T12:08-0700"
			}
			]


	}



	#===============================================================================
	#Uncomment this line to require oauth connections to http server
	#service.oauth: "org.kairosdb.core.oauth.OAuthModule"

	#OAuth consumer keys and secrets in the form
	#oauth.consumer: {
	# [consumer key]: "[consumer secret]"
	#}

	#===============================================================================
	# Determines if cache files are deleted after being used or not.
	# In some cases the cache file can be used again to speed up subsequent queries
	# that query the same metric but aggregate the results differently.
	query_cache.keep_cache_files: false

	# Cache file cleaning schedule. Uses Quartz Cron syntax - this only matters if
	# keep_cache_files is set to true
	query_cache.cache_file_cleaner_schedule: "0 0 12 ? * SUN *"

	#By default the query cache is located in kairos_cache under the system temp folder as
	#defined by java.io.tmpdir system property.  To override set the following value
	#query_cache.cache_dir: ""

	#===============================================================================
	# Log long running queries, set this to true to record long running queries
	# into kairos as the following metrics.
	# kairosdb.log.query.remote_address - String data point that is the remote address
	#   of the system making the query
	# kairosdb.log.query.json - String data point that is the query sent to Kairos
	log.queries: {
		enable: false

		# Time to live to apply to the above metrics.  This helps limit the mount of space
		# used for storing the query information
		ttl: 86400

		# Time in seconds.  If the query request time is longer than this value the query
		# will be written to the above metrics
		greater_than: 60
	}

	# When set to true the query stats are aggregated into min, max, avg, sum, count
	# Setting to true will also disable the above log feature.
	# Set this to true on Kairos nodes that receive large numbers of queries to save
	# from inserting data witch each query
	queries.aggregate_stats = false

	# If a tag filter value begins with this string the remaining is considered a
	# regex to match against those tag values.  ei {"host": "regex:server1[0-2]"}
	# matches host tag values server10, server11 and server12
	# set the value to an empty string to disable
	queries.regex_prefix = "regex:"

	#When set to true Kairos will insert the query into the response json as
	#original_query.  This is useful for some processes that send queries asynchronously
	#and need a way to identify responses.
	queries.return_query_in_response = false

	#===============================================================================
	# Health Checks
	service.health: "org.kairosdb.core.health.HealthCheckModule"

	#Response code to return from a call to /api/v1/health/check
	#Some load balancers want 200 instead of 204
	health.healthyResponseCode: 204

	#===============================================================================
	#Ingest queue processor
	# The MemoryQueueProcessor keeps everything in memory before batching to
	# cassandra and blocks when the queue is full
	# The FileQueueProcessor uses a hybrid memory queue and a file backed queue
	# Data is placed in both memory and in the file queue before a client response
	# is sent.  Data is read from file only when the lag is greater than what the
	# memory queue can hold

	queue_processor: {
		#class: "org.kairosdb.core.queue.MemoryQueueProcessor"
		class: "org.kairosdb.core.queue.FileQueueProcessor"

		# The number of data points to send to Cassandra
		# For the best performance you will want to set this to 10000 but first
		# you will need to change the following values in your cassandra.yaml
		# batch_size_warn_threshold_in_kb: 50
		# batch_size_fail_threshold_in_kb: 70
		# You may need to adjust the above numbers to fit your insert patterns.
		# The CQL batch has a hard limit of 65535 items in a batch, make sure to stay
		# under this as a single data point can generate more than one insert into Cassandra
		# You will want to multiply this number by the number of hosts in the Cassandra
		# cluster.  A batch is pulled from the queue and then divided up depending on which
		# host the data is destined for.
		# If you set this value higher you may also get warnings in C* about Unlogged batches
		# covering x number of partitions.  You can remove this warning by increaseing the value
		# of this property in cassandra.yaml
		# unlogged_batch_across_partitions_warn_threshold: 100
		batch_size: 200

		# If the queue doesn't have at least this many items to process the process thread
		# will pause for .5 seconds to wait for more before grabbing data from the queue.
		# This is an attempt to prevent chatty inserts which can cause extra load on
		# Cassandra
		min_batch_size: 100

		# If the number of items in the process queue is less than {min_batch_size} the
		# queue processor thread will wait this many milliseconds before flushing the data
		# to C*.  This is to prevent single chatty inserts.  This only has effect when
		# data is trickling in to Kairos.
		min_batch_wait: 500

		# The size (number of data points) of the memory queue
		# In the case of FileQueueProcessor:
		# Ingest data is written to the memory queue as well as to disk.  If the system gets
		# behind the memory queue is overrun and data is read from disk until it can
		# catch up.
		# In the case of MemoryQueueProcessor it defines the size of the memory queue.
		memory_queue_size: 100000

		# The number of seconds before checkpointing the file backed queue.  In the case of
		# a crash the file backed queue is read from the last checkpoint
		# Only applies to the FileQueueProcessor
		seconds_till_checkpoint: 90

		# Path to the file backed queue
		# Only applies to the FileQueueProcessor
		queue_path: "queue"

		# Page size of the file backed queue 50Mb
		# Only applies to the FileQueueProcessor
		page_size: 52428800
	}

	#Number of threads allowed to insert data to the backend
	#CassandraDatastore is the only use of this executor
	ingest_executor.thread_count = 10


	# The HostManager serivce keeps track of other kairos nodes in the cluster
	# (ie that are talking to the same cassandra cluster).  It does this by
	# writing data to a serivce key and updating it periodically.  The following
	# settings define how often it checks the key for other hosts and when to mark
	# them as inactive.  This is primarily used for balancing rollup jobs
	# check_delay_time_milliseconds must be less than inactive_time_seconds
	host_service_manager: {
		check_delay_time_millseconds: 20000
		inactive_time_seconds: 30
	}

	# This filters and prevents specified metrics from being ingested.
	# This can be used to turn off kairos internal metrics or stop a flow of
	# metrics that have to many tags, etc.  Uncomment the module and then
	# specify the filters to put in place.
	#service.filter: "org.kairosdb.filter.FilterModule"
	filter: {
		# this does exact match filtering
		list: [
			]
		# this does prefix match filtering
		prefix: [
			]
		# this filters using regex's
		regex: [
			]
	}

	# sets the priority of the filter plugin so it can remove events before
	# the datastore gets them.
	eventbus.filter.priority.org.kairosdb.filter.FilterPlugin: 25

	# The metric_index_filter prevents metric names from being inserted into the index of names you can get
	# by using the /api/v1/metricnames call.
	# The primary purpose of this is to keep from poluting the UI with tons of metric names.  Lets say you
	# setup a camera on a busy intersection to count license plates.  You record the count for each plate under
	# a metric named plate_XXXXX where XXXXX is the plate number.  As you can see this would make for a lot of
	# metric names.  Using this filter you can block those names from showing in the UI but you can still query
	# the values by manually typing in the metric name.  Currently only has effect when using Cassandra backend.
	metric_index_filter: {
		# prefix of the metric name to block from the index.
		prefix: []
	}


  #===============================================================================
  # Roll-ups
	#service.rollups=org.kairosdb.rollup.RollUpModule

	# How often the Roll-up Manager queries for new or updated roll-ups\
	#rollups: {
	#	server_assignment {
	#			check_update_delay_millseconds = 10000
	#		}
	#	}
	#===============================================================================


	#===============================================================================
	#Demo and stress modules

	# The demo module will load one years of data into kairos.  The code goes back
	# one year from the present and inserts data every minute.  The data makes a
	# pretty little sign wave.

	#service.demo: "org.kairosdb.core.demo.DemoModule"
	demo: {
		metric_name: "demo_data"
		# number of rows = number of host tags to add to the data. Setting the number_of_rows
		# to 100 means 100 hosts reporting data every minutes, each host has a different tag.
		number_of_rows: 100
		ttl: 0
	}


	# This just inserts data as fast as it can for the duration specified.  Good for
	# stress testing your backend.  I have found that a single Kairos node will only
	# send about 500k/sec because of a limitation in the cassandra client.

	#service.blast: "org.kairosdb.core.blast.BlastModule"
	# The number_of_rows translates into a random number between 0 and number_of_rows
	# that is added as a tag to each data point.  Trying to simulate a even distribution
	# data in the cluster.
	blast: {
		number_of_rows: 1000
		duration_seconds: 30
		metric_name: "blast_load"
		ttl: 600
	}
}

# Cassandra driver settingst for write cluster
write_cluster: {
	basic: {
		# name of the cluster as it shows up in client specific metrics
		session-name: "write_cluster"
		session-keyspace: "kairosdb"
		config-reload-interval: 0

		contact-points = ["127.0.0.1:9042"]
		#basic.contact-points = ["kairos01:9042", "kairos02:9042", "kairos03:9042"]

		request.default-idempotence: true

		application.name: "kairosdb"
	}

	advanced: {
		connection: {
			pool.local.size: 1

			max-requests-per-connection: 1024
		}

		timestamp-generator: {
			# May not need this, test TWCS to make sure it works.
		}

		# to replace start-async
		reconnect-on-init: false
		reconnection-policy: {
			class: "ExponentialReconnectionPolicy"
			base-delay: 1 second
			max-delay: 5 seconds
		}

		protocol.compression: "lz4"
	}

	profiles: {
		ingest: {
			basic.request.consistency: "QUORUM"
		}

		query: {
			basic.request.consistency: "ONE"
		}
	}
}


